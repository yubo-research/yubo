# Gymnasium BipedalWalker-v3 (bw-heur tag), PPO with PufferLib backend on CUDA.
# Run: python -m rl.algos.runner --config configs/rl/gymnasium/bw/ppo_puffer_cuda.toml

[rl]
algo = "ppo"
backend = "pufferlib"

[rl.ppo]
exp_dir = "_tmp/gymnasium/bw/ppo_puffer_cuda"
env_tag = "bw-heur"
seed = 1

# PPO core
total_timesteps = 3000000
learning_rate = 3e-4
anneal_lr = true
gamma = 0.99
gae_lambda = 0.95

# Rollout/update shape
num_envs = 16
num_steps = 512
num_minibatches = 16
update_epochs = 10
norm_adv = true
clip_coef = 0.2
clip_vloss = true
ent_coef = 0.0
vf_coef = 0.5
max_grad_norm = 0.5
target_kl = 0.02

# Eval: same denoised contract used by TorchRL PPO.
eval_interval = 1
num_denoise_eval = 1
num_denoise_passive_eval = 3
eval_seed_base = 1000
eval_noise_mode = "frozen"
checkpoint_interval = 50

# Save end-of-run videos from evaluation rollouts.
video_enable = true
video_prefix = "ppo_puffer_bw_cuda"
video_num_episodes = 8
video_num_video_episodes = 3
video_episode_selection = "best"
video_seed_base = 1000

# Puffer vector backend knobs
vector_backend = "multiprocessing"
vector_num_workers = 8
vector_batch_size = 16
vector_overwork = false
framestack = 1

# MLP backbone/head defaults for vector-state control
backbone_name = "mlp"
backbone_hidden_sizes = [128, 128]
backbone_activation = "silu"
backbone_layer_norm = true
actor_head_hidden_sizes = []
critic_head_hidden_sizes = []
head_activation = "silu"
share_backbone = true
log_std_init = -0.5

device = "cuda"
log_interval = 1

[rl.run]
seeds = [1]
workers = 1
